# -*- coding: utf-8 -*-
"""tweets.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m7indm8ZfBLON1X4BxuPz3BEh8uqaOtR
"""

import warnings
warnings.simplefilter('ignore')

from google.colab import drive 
drive.mount('/content/drive')

cd /content/drive/Shared\ drives/2021_IR_437_537/Project/Inverted_index_small_run_results/

import nltk
nltk.download('punkt')

import pandas as pd
import pandas as pd
import numpy as np
import pandas as pd
import nltk
import re
import string
from collections import Counter
from nltk.stem import WordNetLemmatizer
from nltk.stem.porter import PorterStemmer
nltk.download('stopwords')
nltk.download('wordnet')
string.punctuation
stopwords = nltk.corpus.stopwords.words('english')
pd.set_option('display.max_rows', 100)
from collections import Counter
from nltk.stem.snowball import SnowballStemmer

df = pd.read_csv('texts.csv')
##df = df_original.iloc[1040000:1050000]
df.shape

#df_original

#df = df_original.head(10000)
#df

df.head(15)

df.shape

def remove_title(content):
  
  content = content[character_remove:]
  return content
def split_it(a):
    return  re.sub('[\r\n\r\n]', ' ', a)

df["content_new"] = df.apply(lambda x: remove_title(x["content"]), axis = 1)

df["content_new"]= df['content_new'].apply(split_it)

def remove_punctuation(text):
    punctuationfree="".join([i for i in text if i not in string.punctuation])
    return punctuationfree
df['content_new']= df['content_new'].apply(lambda x:remove_punctuation(x))
df['content_new'] = df['content_new'].apply(lambda x: x.lower())#lower

def preprocess(sentence):# remove number
    sentence=str(sentence)
    rem_num = re.sub('[0-9]+', '', sentence)
    return rem_num
df['content_new'] = df['content_new'].map(lambda s:preprocess(s))

def preprocess1(sentence):
    sentence= str(sentence)
    rem_num = re.sub('[^a-zA-Z0-9]+',' ', sentence)
    cleaned_string = re.sub('\s+',' ', rem_num)
    return cleaned_string 
df['content_new'] = df['content_new'].map(lambda s:preprocess1(s))

df['content_new'] = df.apply(lambda row: nltk.word_tokenize(row['content_new']), axis=1)#tokenize

def remove_stopwords(text):#stopword remove
    output= [i for i in text if i not in stopwords]
    return output
df['content_new'] = df['content_new'].apply(lambda x:remove_stopwords(x))
#df

wordnet_lemmatizer = WordNetLemmatizer()
def lemmatizer(text):
    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]
    return lemm_text
df['content_new'] = df['content_new'].apply(lambda x:lemmatizer(x))

porter_stemmer = PorterStemmer()
def stemming(text):
    stem_text = [porter_stemmer.stem(word) for word in text]
    return stem_text
df['content_new'] = df['content_new'].apply(lambda x: stemming(x))

r, c = df.shape

df.head()

a = pd.DataFrame(columns = ['word',  'id'])
for i in range(r):  
    s1= df.iloc[i,3]
    s1 = list(set(s1))
    p = pd.DataFrame(s1)
    p = p.rename(columns={0: 'word'})
    p['id']= df.iloc[i,2]
    a =pd.concat([a, p])

#a

f2= a['id'].groupby([a.word]).apply(list).reset_index()
f2.to_csv("inverted_1040000_1050000.csv")

#f2.shape



